{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg1gLoS979Oz",
        "outputId": "6910f12f-6f32-4656-f54c-903e6697d7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data collection and enrichment complete! Saved to scraped_data_team_26.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Replace with your actual API Key and Custom Search Engine ID\n",
        "API_KEY = 'AIzaSyAMik9fEN0HO_DZ84KusiXcuoZOmVAE0qY'  # Replace with your API Key\n",
        "CSE_ID = '9725758fc8d4141c6'  # Replace with your Custom Search Engine ID\n",
        "\n",
        "# Function to perform a Google Search using the Custom Search API\n",
        "def google_search(query, api_key, cse_id, start_index=1):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
        "    res = service.cse().list(q=query, cx=cse_id, start=start_index).execute()\n",
        "    return res.get('items', [])\n",
        "\n",
        "# Function to collect data from the search results\n",
        "def collect_data(query, num_results=100):\n",
        "    data = []\n",
        "    start_index = 1\n",
        "    while len(data) < num_results:\n",
        "        try:\n",
        "            results = google_search(query, API_KEY, CSE_ID, start_index)\n",
        "            if not results:\n",
        "                break\n",
        "            for item in results:\n",
        "                # Extracting the data from each search result item\n",
        "                title = item.get('title')\n",
        "                link = item.get('link')\n",
        "                snippet = item.get('snippet')\n",
        "                displayLink = item.get('displayLink')\n",
        "\n",
        "                # Store the extracted data\n",
        "                data.append({\n",
        "                    'Title': title,\n",
        "                    'Link': link,\n",
        "                    'Snippet': snippet,\n",
        "                    'DisplayLink': displayLink\n",
        "                })\n",
        "            start_index += 10  # API fetches 10 results per page\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            break\n",
        "    return data[:num_results]\n",
        "\n",
        "# Function to enrich data with additional columns\n",
        "def enrich_data(df):\n",
        "    df['Event Type'] = df['Title'].apply(lambda x: 'Anime & Comics Cosplay Festival' if 'Anime & Comics' in x else 'Other')\n",
        "    df['Event Date'] = df['Snippet'].str.extract(r'(\\b[A-Za-z]+\\s\\d{1,2},\\s\\d{4}\\b)')  # Extract the event date\n",
        "    df['Venue'] = df['Snippet'].str.extract(r'at\\s([A-Za-z\\s]+)')  # Extract venue name after 'at'\n",
        "    df['Language'] = 'English'\n",
        "    df['Price Range'] = df['Snippet'].str.extract(r'(\\$\\d+\\s?-\\s?\\$\\d+)')\n",
        "    df['Keywords'] = df['Snippet'].apply(lambda x: ', '.join(x.split()[:5]))\n",
        "    df['Region'] = 'Baku'\n",
        "    df['Category'] = 'General'\n",
        "    df['Source'] = df['DisplayLink']\n",
        "    df['Event Name'] = df['Title']\n",
        "    df['Link'] = df['Link']\n",
        "    df['Event Details'] = df['Snippet']\n",
        "    return df\n",
        "\n",
        "# Query: Searching for event-related information on tickets-az.com\n",
        "query = \"site:tickets-az.com/en/baku/events\"\n",
        "num_results = 100\n",
        "\n",
        "# Collect the data\n",
        "results = collect_data(query, num_results)\n",
        "\n",
        "# Create a DataFrame to structure the data\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Enrich the data with additional columns\n",
        "df = enrich_data(df)\n",
        "\n",
        "# Ensure the 'data' folder exists\n",
        "data_folder = \"data\"\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "# Save to CSV in the 'data' folder\n",
        "csv_filename = os.path.join(data_folder, 'scraped_data_team_26.csv')  # Adjust the filename as needed\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"Data collection and enrichment complete! Saved to {csv_filename}\")"
      ]
    }
  ]
}